{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ebf3da",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "The purpose of this notebook is to experiment with using neural networks to predict the vehicle's steering angle from the camera feed. This is useful for the visual odometry aspect of the SLAM algorithm, since previous versions of RatSLAM have used crude approximation methods that also depended on dataset-specific constants.\n",
    "\n",
    "This notebook is heavily influenced by this [PilotNet tutorial notebook](https://github.com/lava-nc/lava-dl/blob/main/tutorials/lava/lib/dl/slayer/pilotnet/train.ipynb) from Lava-DL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b207b04",
   "metadata": {},
   "source": [
    "We will be using Sigma-Delta neural networks, which are explained well in this [Lava tutorial](https://github.com/lava-nc/lava/blob/main/tutorials/in_depth/tutorial10_sigma_delta_neurons.ipynb). The key idea is that in dashboard camera footage for example, temporal signals are slow and don't change in shorter time-scales. The conventional ANN approach requires computation at every time-step, even if the information is redundant. Instead, we can enforce the temporal signal using a delta-encoder, which only sends activations to the next layer when the encoded message magnitude is larger than a threshold. The sigma decoder unit accumulates the sparse event messages to restore the original value.\n",
    "\n",
    "In this notebook, we will be using the PilotNet Dataset seen in the link above, which features dashcam footage of a car driving around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc90842",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "\n",
    "First, follow these instructions to download the dataset: [PilotNet Datasets](https://github.com/lhzlhz/PilotNet/tree/master/data/datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb1732c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "\n",
    "from pilotnet_dataset import PilotNetDataset\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01671ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_rate_loss(x, max_rate=0.01):\n",
    "    mean_event_rate = torch.mean(torch.abs(x))\n",
    "    return F.mse_loss(F.relu(mean_event_rate - max_rate), torch.zeros_like(mean_event_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4506ab38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        \n",
    "        sdnn_params = { # sigma-delta neuron parameters\n",
    "                'threshold'     : 0.1,    # delta unit threshold\n",
    "                'tau_grad'      : 0.5,    # delta unit surrogate gradient relaxation parameter\n",
    "                'scale_grad'    : 1,      # delta unit surrogate gradient scale parameter\n",
    "                'requires_grad' : True,   # trainable threshold\n",
    "                'shared_param'  : True,   # layer wise threshold\n",
    "                'activation'    : F.relu, # activation function\n",
    "            }\n",
    "        sdnn_cnn_params = { # conv layer has additional mean only batch norm\n",
    "                **sdnn_params,                                 # copy all sdnn_params\n",
    "                'norm' : slayer.neuron.norm.MeanOnlyBatchNorm, # mean only quantized batch normalizaton\n",
    "            }\n",
    "        sdnn_dense_params = { # dense layers have additional dropout units enabled\n",
    "                **sdnn_cnn_params,                        # copy all sdnn_cnn_params\n",
    "                'dropout' : slayer.neuron.Dropout(p=0.2), # neuron dropout\n",
    "            }\n",
    "        \n",
    "        self.blocks = torch.nn.ModuleList([# sequential network blocks \n",
    "                # delta encoding of the input\n",
    "                slayer.block.sigma_delta.Input(sdnn_params), \n",
    "                # convolution layers\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params,  3, 24, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 24, 36, 3, padding=0, stride=2, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 36, 64, 3, padding=(1, 0), stride=(2, 1), weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Conv(sdnn_cnn_params, 64, 64, 3, padding=0, stride=1, weight_scale=2, weight_norm=True),\n",
    "                # flatten layer\n",
    "                slayer.block.sigma_delta.Flatten(),\n",
    "                # dense layers\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params, 64*40, 100, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params,   100,  50, weight_scale=2, weight_norm=True),\n",
    "                slayer.block.sigma_delta.Dense(sdnn_dense_params,    50,  10, weight_scale=2, weight_norm=True),\n",
    "                # linear readout with sigma decoding of output\n",
    "                slayer.block.sigma_delta.Output(sdnn_dense_params,   10,   1, weight_scale=2, weight_norm=True)\n",
    "            ])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        count = []\n",
    "        event_cost = 0\n",
    "\n",
    "        for block in self.blocks: \n",
    "            # forward computation is as simple as calling the blocks in a loop\n",
    "            x = block(x)\n",
    "            if hasattr(block, 'neuron'):\n",
    "                event_cost += event_rate_loss(x)\n",
    "                count.append(torch.sum(torch.abs(((x[..., 1:]) > 0).int()).to(x.dtype)).item())\n",
    "\n",
    "        return x, event_cost, torch.FloatTensor(count).reshape((1, -1)).to(x.device)\n",
    "\n",
    "    def grad_flow(self, path):\n",
    "        # helps monitor the gradient flow\n",
    "        grad = [b.synapse.grad_norm for b in self.blocks if hasattr(b, 'synapse')]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.semilogy(grad)\n",
    "        plt.savefig(path + 'gradFlow.png')\n",
    "        plt.close()\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def export_hdf5(self, filename):\n",
    "        # network export to hdf5 format\n",
    "        h = h5py.File(filename, 'w')\n",
    "        layer = h.create_group('layer')\n",
    "        for i, b in enumerate(self.blocks):\n",
    "            b.export_hdf5(layer.create_group(f'{i}'))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143ef90",
   "metadata": {},
   "source": [
    "## Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d5f5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch  = 8  # batch size\n",
    "lr     = 0.001 # leaerning rate\n",
    "lam    = 0.01  # lagrangian for event rate loss\n",
    "epochs = 200  # training epochs\n",
    "steps  = [60, 120, 160] # learning rate reduction milestones\n",
    "\n",
    "trained_folder = 'Trained'\n",
    "logs_folder = 'Logs'\n",
    "\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "os.makedirs(logs_folder   , exist_ok=True)\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0f56f",
   "metadata": {},
   "source": [
    "## Instantiating and Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1718a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network().to(device)\n",
    "\n",
    "optimizer = torch.optim.RAdam(net.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# Datasets\n",
    "training_set = PilotNetDataset(\n",
    "    train=True, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([33, 100]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]), \n",
    ")\n",
    "testing_set = PilotNetDataset(\n",
    "    train=False, \n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize([33, 100]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    ]),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch, shuffle=True, num_workers=8)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch, shuffle=True, num_workers=8)\n",
    "\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(\n",
    "        net=net,\n",
    "        error=lambda output, target: F.mse_loss(output.flatten(), target.flatten()),\n",
    "        optimizer=optimizer,\n",
    "        stats=stats,\n",
    "        count_log=True,\n",
    "        lam=lam\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8025d837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   0/200] Train loss =     0.32538                          accuracy = 0.00000 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         param_group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, ground_truth) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader): \u001b[38;5;66;03m# training loop\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m     \u001b[43massistant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m3d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (\u001b[38;5;28minput\u001b[39m, ground_truth) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_loader): \u001b[38;5;66;03m# testing loop\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/VIP/rg-slam/lava-dl/src/lava/lib/dl/slayer/utils/assistant.py:118\u001b[0m, in \u001b[0;36mAssistant.train\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    116\u001b[0m         output, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         output, net_loss, count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlam \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ratslam/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[26], line 47\u001b[0m, in \u001b[0;36mNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m event_cost \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks: \n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# forward computation is as simple as calling the blocks in a loop\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(block, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneuron\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     49\u001b[0m         event_cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m event_rate_loss(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ratslam/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/VIP/rg-slam/lava-dl/src/lava/lib/dl/slayer/block/base.py:698\u001b[0m, in \u001b[0;36mAbstractConv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward computation method. The input must be in ``NCHWT`` format.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    697\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msynapse(x)\n\u001b[0;32m--> 698\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelay_shift \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    700\u001b[0m     x \u001b[38;5;241m=\u001b[39m step_delay(\u001b[38;5;28mself\u001b[39m, x)\n",
      "File \u001b[0;32m~/miniconda3/envs/ratslam/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/VIP/rg-slam/lava-dl/src/lava/lib/dl/slayer/neuron/sigma_delta.py:203\u001b[0m, in \u001b[0;36mNeuron.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    195\u001b[0m     axon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelta(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\n\u001b[1;32m    197\u001b[0m             dend \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39munsqueeze(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m             )\n\u001b[1;32m    201\u001b[0m         ))\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     axon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelta\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# axon = self.quantize_8bit(axon*2)/2\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \n\u001b[1;32m    207\u001b[0m \u001b[38;5;66;03m# axon computation\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/ratslam/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/VIP/rg-slam/lava-dl/src/lava/lib/dl/slayer/axon/delta.py:304\u001b[0m, in \u001b[0;36mDelta.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     _error_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 304\u001b[0m output, residual_state, error_state \u001b[38;5;241m=\u001b[39m \u001b[43m_DeltaUnit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pre_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_residual_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_error_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcum_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtau_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpersistent_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[0;32m~/Documents/VIP/rg-slam/lava-dl/src/lava/lib/dl/slayer/axon/delta.py:47\u001b[0m, in \u001b[0;36m_DeltaUnit.forward\u001b[0;34m(ctx, input, threshold, pre_state, residual_state, error_state, cum_error, tau_grad, scale_grad)\u001b[0m\n\u001b[1;32m     44\u001b[0m delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m-\u001b[39m pre_state \u001b[38;5;241m+\u001b[39m residual_state\n\u001b[1;32m     45\u001b[0m delta_input[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m=\u001b[39m delta\n\u001b[1;32m     46\u001b[0m output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m---> 47\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold,\n\u001b[1;32m     48\u001b[0m     delta,\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m*\u001b[39m delta\n\u001b[1;32m     50\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     51\u001b[0m residual_state \u001b[38;5;241m=\u001b[39m (delta \u001b[38;5;241m-\u001b[39m output[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t])\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m     52\u001b[0m pre_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, t]\u001b[38;5;241m.\u001b[39mdetach()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    if epoch in steps:\n",
    "        for param_group in optimizer.param_groups:    \n",
    "            print('\\nLearning rate reduction from', param_group['lr'])\n",
    "            param_group['lr'] /= 10/3\n",
    "        \n",
    "    for i, (input, ground_truth) in enumerate(train_loader): # training loop\n",
    "        assistant.train(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "    \n",
    "    for i, (input, ground_truth) in enumerate(test_loader): # testing loop\n",
    "        assistant.test(input, ground_truth)\n",
    "        print(f'\\r[Epoch {epoch:3d}/{epochs}] {stats}', end='')\n",
    "        \n",
    "    if epoch%50==49: print() \n",
    "    if stats.testing.best_loss:  \n",
    "        torch.save(net.state_dict(), trained_folder + '/network.pt')\n",
    "    stats.update()\n",
    "    stats.save(trained_folder + '/')\n",
    "    \n",
    "    # gradient flow monitoring\n",
    "    net.grad_flow(trained_folder + '/')\n",
    "    \n",
    "    # checkpoint saves\n",
    "    if epoch%10 == 0:\n",
    "        torch.save({'net': net.state_dict(), 'optimizer': optimizer.state_dict()}, logs_folder + f'/checkpoint{epoch}.pt')        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a857e7",
   "metadata": {},
   "source": [
    "## Learning plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2794061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats.plot(figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2380e78",
   "metadata": {},
   "source": [
    "## Comparison of operations in SDNN vs ANN\n",
    "This can be a good approach for evaluating/obtaining metrics for SLAM performance comparisons. The following cells will compare the synaptic operation and neuron activity of the trained SDNN and ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbc40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for i, (input, ground_truth) in enumerate(test_loader):\n",
    "    _, count = assistant.test(input, ground_truth)\n",
    "    count = (count.flatten()/(input.shape[-1]-1)/input.shape[0]).tolist() # count skips first events\n",
    "    counts.append(count) \n",
    "    print('\\rEvent count : ' + ', '.join([f'{c:.4f}' for c in count]), f'| {stats.testing}', end='') \n",
    "        \n",
    "counts = np.mean(counts, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5178c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.compare_ops(net, counts, mse=stats.testing.min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60fa6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
